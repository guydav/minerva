{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import warnings\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_no_unknown.loc[np.logical_not(data_no_unknown.pedestrian_location == data_no_unknown.pedestrian_location), 'pedestrian_location'] = ''\n",
    "# data_no_unknown.loc[np.logical_not(data_no_unknown.pedestrian_movement == data_no_unknown.pedestrian_movement), 'pedestrian_movement'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casualty_class</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>severe</th>\n",
       "      <th>pedestrian_location</th>\n",
       "      <th>pedestrian_movement</th>\n",
       "      <th>travel</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>passenger</td>\n",
       "      <td>female</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>motorbike</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passenger</td>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>car</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passenger</td>\n",
       "      <td>male</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>car</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passenger</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger</td>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>motorbike</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  casualty_class  gender age  severe pedestrian_location pedestrian_movement  \\\n",
       "0      passenger  female  33       0                                           \n",
       "1      passenger  female  20       0                                           \n",
       "2      passenger    male  52       0                                           \n",
       "3      passenger  female  17       0                                           \n",
       "4      passenger  female  20       0                                           \n",
       "\n",
       "       travel  year  \n",
       "0   motorbike  2007  \n",
       "1         car  2005  \n",
       "2         car  2006  \n",
       "3  pedestrian  2012  \n",
       "4   motorbike  2010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casualty_data = pandas.read_csv('./casualty_train.csv')\n",
    "data_no_unknown = casualty_data.loc[casualty_data.age != 'Unknown']\n",
    "data_no_unknown.loc[np.logical_not(data_no_unknown.pedestrian_location == data_no_unknown.pedestrian_location), 'pedestrian_location'] = ''\n",
    "data_no_unknown.loc[np.logical_not(data_no_unknown.pedestrian_movement == data_no_unknown.pedestrian_movement), 'pedestrian_movement'] = ''\n",
    "data_no_unknown.severe = data_no_unknown.severe.astype('int')\n",
    "data_no_unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((194949, 8), (21661, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data_no_unknown, test_size=0.1, random_state=RANDOM_SEED,\n",
    "                               stratify=data_no_unknown.casualty_class, ) #  train_size = 0.25,\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# casualty_data.loc[casualty_data.age == 'Unknown'].groupby('casualty_class').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casualty_class_driver', 'casualty_class_passenger', 'casualty_class_pedestrian', 'gender', 'age', 'travel_bicycle', 'travel_bus', 'travel_car', 'travel_motorbike', 'travel_other', 'travel_pedestrian', 'travel_taxi', 'year']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  1.        , -1.099384  ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.19920703],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        , -0.31618757,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.85600581],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  0.22602534,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.51280458],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.88873001,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.85600581],\n",
       "       [ 1.        ,  0.        ,  0.        ,  1.        ,  1.73217232,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.86000031]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mapper = DataFrameMapper([\n",
    "    ('casualty_class', sklearn.preprocessing.LabelBinarizer()),\n",
    "    ('gender', sklearn.preprocessing.LabelBinarizer()),\n",
    "    (['age'], sklearn.preprocessing.StandardScaler()),\n",
    "#     ('pedestrian_location', sklearn.preprocessing.LabelBinarizer()),\n",
    "#     ('pedestrian_movement', sklearn.preprocessing.LabelBinarizer()),\n",
    "    ('travel', sklearn.preprocessing.LabelBinarizer()),\n",
    "    (['year'], sklearn.preprocessing.StandardScaler()),\n",
    "])\n",
    "\n",
    "transformed_data = data_mapper.fit_transform(train.copy())\n",
    "print(data_mapper.transformed_names_)\n",
    "transformed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM]0.262333333333 [ 0.261  0.264  0.262]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(33)\n",
    "\n",
    "# Fun fact: if you fit a logit without class weights, it always predicts 0. Womp womp.\n",
    "\n",
    "pipe = sklearn.pipeline.Pipeline([\n",
    "    ('featurize', data_mapper),\n",
    "#     ('select', sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_regression)),\n",
    "    ('svm', sklearn.svm.SVC(cache_size=1024, kernel='rbf', class_weight='balanced', verbose=True))\n",
    "#     ('logit', sklearn.linear_model.LogisticRegression(class_weight='balanced', verbose=True))\n",
    "])\n",
    "\n",
    "# pipe.fit(train, train.severe)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "        cv_scores = np.round(cross_val_score(pipe, X=train, y=train.severe, scoring='f1', cv=3), 3)\n",
    "        print(np.average(cv_scores), cv_scores)\n",
    "    \n",
    "#     for k in range(6, 16):\n",
    "#         pipe.set_params(select__k=k)\n",
    "#         shuffled = train.sample(frac=1)\n",
    "#         cv_scores = np.round(cross_val_score(pipe, X=shuffled, y=shuffled.severe, scoring='f1', cv=5), 3)\n",
    "#         print(k, np.average(cv_scores), cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194949, 8) (194949,)\n",
      "[LibLinear][LibLinear][LibLinear]0.269333333333 [ 0.268  0.271  0.269]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(33)\n",
    "\n",
    "# Fun fact: if you fit a logit without class weights, it always predicts 0. Womp womp.\n",
    "\n",
    "logit_pipe = sklearn.pipeline.Pipeline([\n",
    "    ('featurize', data_mapper),\n",
    "#     ('select', sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_regression)),\n",
    "#     ('svm', sklearn.svm.SVC(cache_size=1024, kernel='linear', class_weight='balanced', verbose=True))\n",
    "    ('logit', sklearn.linear_model.LogisticRegression(verbose=True))\n",
    "])\n",
    "\n",
    "# pipe.fit(train, train.severe)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "#     weights = train.severe + 1\n",
    "#     print(train.shape, weights.shape)\n",
    "#     cv_scores = np.round(cross_val_score(logit_pipe, X=train, y=train.severe, scoring='f1', cv=3, \n",
    "# #                                          fit_params=dict(logit__sample_weight=weights)\n",
    "#                                         ), 3)\n",
    "#     print(np.average(cv_scores), cv_scores)\n",
    "    \n",
    "    for one_class_weight in np.random.rand:\n",
    "        pipe.set_params(select__k=k)\n",
    "        shuffled = train.sample(frac=1)\n",
    "        cv_scores = np.round(cross_val_score(pipe, X=shuffled, y=shuffled.severe, scoring='f1', cv=5), 3)\n",
    "        print(k, np.average(cv_scores), cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to randomly search over 1-class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.93      0.73     12406\n",
      "          1       0.64      0.16      0.26      9255\n",
      "\n",
      "avg / total       0.62      0.60      0.53     21661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logit_pipe.fit(train, train.severe)\n",
    "print(classification_report(logit_pipe.predict(test), test.severe,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   45.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Model with rank: 1\n",
      "Mean validation score: 0.274 (std: 0.002)\n",
      "Parameters: {'logit__C': 9.8062818421524138, 'logit__class_weight': {0: 1, 1: array([ 5.94063468])}}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.274 (std: 0.002)\n",
      "Parameters: {'logit__C': 7.8045080473103923, 'logit__class_weight': {0: 1, 1: array([ 5.86588127])}}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.272 (std: 0.002)\n",
      "Parameters: {'logit__C': 3.4851012743772993, 'logit__class_weight': {0: 1, 1: array([ 5.49975421])}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "logit_search_pipe = sklearn.pipeline.Pipeline([\n",
    "    ('featurize', data_mapper),\n",
    "#     ('select', sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_regression)),\n",
    "    ('logit', sklearn.linear_model.LogisticRegression(verbose=True))\n",
    "])\n",
    "\n",
    "from collections import namedtuple\n",
    "ClassWeightSampler = namedtuple('ClassWeightSampler', 'rvs')\n",
    "\n",
    "def sample_class_weights(loc=0, scale=1, size=1, random_state=None):\n",
    "    return {0: 1, 1: uniform.rvs(loc=1, scale=10, size=size, random_state=random_state)}\n",
    "\n",
    "sampler = ClassWeightSampler(rvs=sample_class_weights)\n",
    "\n",
    "# report function from http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    search_cv = RandomizedSearchCV(logit_search_pipe, n_iter=10, scoring='f1', n_jobs=4, \n",
    "                                   verbose=1, random_state=RANDOM_SEED,\n",
    "                                   param_distributions={'logit__class_weight': sampler,\n",
    "                                                        'logit__C': uniform(loc=1, scale=10) \n",
    "                                                       })\n",
    "    search_cv.fit(X=train, y=train.severe)\n",
    "    report(search_cv.cv_results_)\n",
    "\n",
    "#     for one_class_weight in np.random.rand:\n",
    "#         pipe.set_params(select__k=k)\n",
    "#         shuffled = train.sample(frac=1)\n",
    "#         cv_scores = np.round(cross_val_score(pipe, X=shuffled, y=shuffled.severe, scoring='f1', cv=5), 3)\n",
    "#         print(k, np.average(cv_scores), cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.92      0.82     15597\n",
      "          1       0.47      0.19      0.27      6064\n",
      "\n",
      "avg / total       0.67      0.71      0.67     21661\n",
      "\n",
      "accuracy_score\n",
      "0.714509948756\n",
      "roc_auc_score\n",
      "0.552748239885\n",
      "mutual_info_score\n",
      "0.0105637229065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, mutual_info_score\n",
    "\n",
    "test_predictions = search_cv.best_estimator_.predict(test)\n",
    "\n",
    "for metric in (classification_report, accuracy_score, roc_auc_score, mutual_info_score):\n",
    "    print(metric.__name__)\n",
    "    print(metric(test_predictions, test.severe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casualty_class</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>severe</th>\n",
       "      <th>pedestrian_location</th>\n",
       "      <th>pedestrian_movement</th>\n",
       "      <th>travel</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>passenger</td>\n",
       "      <td>male</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passenger</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pedestrian</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passenger</td>\n",
       "      <td>female</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>car</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passenger</td>\n",
       "      <td>male</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>car</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>car</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  casualty_class  gender age  severe pedestrian_location pedestrian_movement  \\\n",
       "0      passenger    male  32       1                                           \n",
       "1      passenger    male  34       0                                           \n",
       "2      passenger  female  57       0                                           \n",
       "3      passenger    male  37       0                                           \n",
       "4      passenger  female  23       0                                           \n",
       "\n",
       "       travel  year  \n",
       "0  pedestrian  2013  \n",
       "1  pedestrian  2008  \n",
       "2         car  2010  \n",
       "3         car  2011  \n",
       "4         car  2007  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data = pandas.read_csv('./casualty_test.csv')\n",
    "new_test_data = new_test_data.loc[new_test_data.age != 'Unknown']\n",
    "new_test_data.loc[np.logical_not(new_test_data.pedestrian_location == new_test_data.pedestrian_location), 'pedestrian_location'] = ''\n",
    "new_test_data.loc[np.logical_not(new_test_data.pedestrian_movement == new_test_data.pedestrian_movement), 'pedestrian_movement'] = ''\n",
    "new_test_data.severe = new_test_data.severe.astype('int')\n",
    "new_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.92      0.82     39071\n",
      "          1       0.49      0.19      0.27     15206\n",
      "\n",
      "avg / total       0.67      0.72      0.67     54277\n",
      "\n",
      "accuracy_score\n",
      "0.717449380032\n",
      "roc_auc_score\n",
      "0.556360603485\n",
      "mutual_info_score\n",
      "0.0120545312642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, mutual_info_score\n",
    "\n",
    "new_test_predictions = search_cv.best_estimator_.predict(new_test_data)\n",
    "\n",
    "for metric in (classification_report, accuracy_score, roc_auc_score, mutual_info_score):\n",
    "    print(metric.__name__)\n",
    "    print(metric(new_test_predictions, new_test_data.severe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10736e5d0, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/guydavidson/anaconda/lib/python3.6/site-p...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/guyda.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10736e5d0, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/guydavidson/anaconda/lib/python3.6/site-p...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/guyda.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 9, 16, 12, 144186, tzinfo=tzutc()), 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'session': '832E0F2676E645F58C0F409E71BD1957', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'832E0F2676E645F58C0F409E71BD1957']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 9, 16, 12, 144186, tzinfo=tzutc()), 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'session': '832E0F2676E645F58C0F409E71BD1957', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'832E0F2676E645F58C0F409E71BD1957'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 9, 16, 12, 144186, tzinfo=tzutc()), 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'session': '832E0F2676E645F58C0F409E71BD1957', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.With object>], cell_name='<ipython-input-18-8492c359b945>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 114a55898, execution_..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x108803150, file \"<ipython-input-18-8492c359b945>\", line 32>\n        result = <ExecutionResult object at 114a55898, execution_..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x108803150, file \"<ipython-input-18-8492c359b945>\", line 32>, result=<ExecutionResult object at 114a55898, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x108803150, file \"<ipython-input-18-8492c359b945>\", line 32>\n        self.user_global_ns = {'ClassWeightSampler': <class '__main__.ClassWeightSampler'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'In': ['', \"new_test_data = pandas.read_csv('./casualty_test...ta.severe.astype('int')\\nnew_test_data.head()\\n\\n = \", \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", \"get_ipython().magic('matplotlib inline')\\n\\nimport...\\nmatplotlib.style.use('ggplot')\\n\\nRANDOM_SEED = 33\", \"# data_no_unknown.loc[np.logical_not(data_no_unk...pedestrian_movement), 'pedestrian_movement'] = ''\", \"casualty_data = pandas.read_csv('./casualty_trai...known.severe.astype('int')\\ndata_no_unknown.head()\", 'from sklearn.model_selection import train_test_s..., ) #  train_size = 0.25,\\ntrain.shape, test.shape', \"# casualty_data.loc[casualty_data.age == 'Unknown'].groupby('casualty_class').sum()\", \"data_mapper = DataFrameMapper([\\n    ('casualty_c...a_mapper.transformed_names_)\\ntransformed_data[:5]\", 'from sklearn.model_selection import RandomizedSe...       print(k, np.average(cv_scores), cv_scores)', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor....__name__, metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...\\n    print(metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', 'from sklearn.metrics import classification_repor...tric(new_test_predictions, new_test_data.severe))', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)'], 'Out': {5:   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , 6: ((194949, 8), (21661, 8)), 8: array([[ 1.        ,  0.        ,  0.        ,  ...\n         0.        ,  0.        , -0.86000031]]), 10:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , 14:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  }, 'RANDOM_SEED': 33, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, '_':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_10':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_14':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_5':   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , ...}\n        self.user_ns = {'ClassWeightSampler': <class '__main__.ClassWeightSampler'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'In': ['', \"new_test_data = pandas.read_csv('./casualty_test...ta.severe.astype('int')\\nnew_test_data.head()\\n\\n = \", \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", \"get_ipython().magic('matplotlib inline')\\n\\nimport...\\nmatplotlib.style.use('ggplot')\\n\\nRANDOM_SEED = 33\", \"# data_no_unknown.loc[np.logical_not(data_no_unk...pedestrian_movement), 'pedestrian_movement'] = ''\", \"casualty_data = pandas.read_csv('./casualty_trai...known.severe.astype('int')\\ndata_no_unknown.head()\", 'from sklearn.model_selection import train_test_s..., ) #  train_size = 0.25,\\ntrain.shape, test.shape', \"# casualty_data.loc[casualty_data.age == 'Unknown'].groupby('casualty_class').sum()\", \"data_mapper = DataFrameMapper([\\n    ('casualty_c...a_mapper.transformed_names_)\\ntransformed_data[:5]\", 'from sklearn.model_selection import RandomizedSe...       print(k, np.average(cv_scores), cv_scores)', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor....__name__, metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...\\n    print(metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', 'from sklearn.metrics import classification_repor...tric(new_test_predictions, new_test_data.severe))', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)'], 'Out': {5:   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , 6: ((194949, 8), (21661, 8)), 8: array([[ 1.        ,  0.        ,  0.        ,  ...\n         0.        ,  0.        , -0.86000031]]), 10:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , 14:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  }, 'RANDOM_SEED': 33, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, '_':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_10':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_14':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_5':   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/guydavidson/projects/minerva/notebooks/CS156/<ipython-input-18-8492c359b945> in <module>()\n     35     search_cv = RandomizedSearchCV(logit_search_pipe, n_iter=10, scoring='recall', n_jobs=4, \n     36                                    verbose=1, random_state=RANDOM_SEED,\n     37                                    param_distributions={'ridge__class_weight': sampler,\n     38 #                                                         'logit__C': uniform(loc=1, scale=10) \n     39                                                        })\n---> 40     search_cv.fit(X=train, y=train.severe)\n     41     report(search_cv.cv_results_)\n     42 \n     43 \n     44 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=None, error_score='raise',...rn_train_score=True, scoring='recall', verbose=1), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...n_train_score=True, scoring='recall', verbose=1)>\n        X =        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns]\n        y = 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=None, error_score='raise',...rn_train_score=True, scoring='recall', verbose=1), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Sep 14 18:16:12 2017\nPID: 4332              Python 3.6.2: /Users/guydavidson/anaconda/bin/python\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, scorer=make_scorer(recall_score), train=array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), test=array([    0,     1,     2, ..., 65014, 65015, 65016]), verbose=1, parameters={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        parameters = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **kwargs={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...01,\n          verbose=True, warm_start=False))])>\n        kwargs = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), steps_attr='steps', **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        params = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    277                 name, sub_name = split\n    278                 if name not in valid_params:\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n--> 282                                      (name, self))\n        name = 'ridge'\n        self = Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))])\n    283                 sub_object = valid_params[name]\n    284                 sub_object.set_params(**{sub_name: value})\n    285             else:\n    286                 # simple objects case\n\nValueError: Invalid parameter ridge for estimator Pipeline(steps=[('featurize', DataFrameMapper(default=False, df_out=False,\n        features=[('casualty_class', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), ('gender', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), (['age'], StandardScaler(copy=True, with_mean=True...'l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=True, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 227, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 180, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 69, in _set_params\n    super(_BasePipeline, self).set_params(**params)\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/base.py\", line 282, in set_params\n    (name, self))\nValueError: Invalid parameter ridge for estimator Pipeline(steps=[('featurize', DataFrameMapper(default=False, df_out=False,\n        features=[('casualty_class', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), ('gender', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), (['age'], StandardScaler(copy=True, with_mean=True...'l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=True, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/guydavidson/anaconda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Sep 14 18:16:12 2017\nPID: 4332              Python 3.6.2: /Users/guydavidson/anaconda/bin/python\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, scorer=make_scorer(recall_score), train=array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), test=array([    0,     1,     2, ..., 65014, 65015, 65016]), verbose=1, parameters={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        parameters = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **kwargs={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...01,\n          verbose=True, warm_start=False))])>\n        kwargs = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), steps_attr='steps', **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        params = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    277                 name, sub_name = split\n    278                 if name not in valid_params:\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n--> 282                                      (name, self))\n        name = 'ridge'\n        self = Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))])\n    283                 sub_object = valid_params[name]\n    284                 sub_object.set_params(**{sub_name: value})\n    285             else:\n    286                 # simple objects case\n\nValueError: Invalid parameter ridge for estimator Pipeline(steps=[('featurize', DataFrameMapper(default=False, df_out=False,\n        features=[('casualty_class', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), ('gender', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), (['age'], StandardScaler(copy=True, with_mean=True...'l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=True, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Sep 14 18:16:12 2017\nPID: 4332              Python 3.6.2: /Users/guydavidson/anaconda/bin/python\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, scorer=make_scorer(recall_score), train=array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), test=array([    0,     1,     2, ..., 65014, 65015, 65016]), verbose=1, parameters={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        parameters = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **kwargs={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...01,\n          verbose=True, warm_start=False))])>\n        kwargs = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), steps_attr='steps', **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        params = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    277                 name, sub_name = split\n    278                 if name not in valid_params:\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n--> 282                                      (name, self))\n        name = 'ridge'\n        self = Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))])\n    283                 sub_object = valid_params[name]\n    284                 sub_object.set_params(**{sub_name: value})\n    285             else:\n    286                 # simple objects case\n\nValueError: Invalid parameter ridge for estimator Pipeline(steps=[('featurize', DataFrameMapper(default=False, df_out=False,\n        features=[('casualty_class', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), ('gender', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), (['age'], StandardScaler(copy=True, with_mean=True...'l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=True, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8492c359b945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#                                                         'logit__C': uniform(loc=1, scale=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                                                        })\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0msearch_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msevere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10736e5d0, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/guydavidson/anaconda/lib/python3.6/site-p...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/guyda.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10736e5d0, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/guydavidson/anaconda/lib/python3.6/site-p...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/guyda.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 9, 16, 12, 144186, tzinfo=tzutc()), 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'session': '832E0F2676E645F58C0F409E71BD1957', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'832E0F2676E645F58C0F409E71BD1957']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 9, 16, 12, 144186, tzinfo=tzutc()), 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'session': '832E0F2676E645F58C0F409E71BD1957', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'832E0F2676E645F58C0F409E71BD1957'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 9, 16, 12, 144186, tzinfo=tzutc()), 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'session': '832E0F2676E645F58C0F409E71BD1957', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '0525213C756B49EB877CBB2F0203C567', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.With object>], cell_name='<ipython-input-18-8492c359b945>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 114a55898, execution_..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x108803150, file \"<ipython-input-18-8492c359b945>\", line 32>\n        result = <ExecutionResult object at 114a55898, execution_..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x108803150, file \"<ipython-input-18-8492c359b945>\", line 32>, result=<ExecutionResult object at 114a55898, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x108803150, file \"<ipython-input-18-8492c359b945>\", line 32>\n        self.user_global_ns = {'ClassWeightSampler': <class '__main__.ClassWeightSampler'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'In': ['', \"new_test_data = pandas.read_csv('./casualty_test...ta.severe.astype('int')\\nnew_test_data.head()\\n\\n = \", \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", \"get_ipython().magic('matplotlib inline')\\n\\nimport...\\nmatplotlib.style.use('ggplot')\\n\\nRANDOM_SEED = 33\", \"# data_no_unknown.loc[np.logical_not(data_no_unk...pedestrian_movement), 'pedestrian_movement'] = ''\", \"casualty_data = pandas.read_csv('./casualty_trai...known.severe.astype('int')\\ndata_no_unknown.head()\", 'from sklearn.model_selection import train_test_s..., ) #  train_size = 0.25,\\ntrain.shape, test.shape', \"# casualty_data.loc[casualty_data.age == 'Unknown'].groupby('casualty_class').sum()\", \"data_mapper = DataFrameMapper([\\n    ('casualty_c...a_mapper.transformed_names_)\\ntransformed_data[:5]\", 'from sklearn.model_selection import RandomizedSe...       print(k, np.average(cv_scores), cv_scores)', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor....__name__, metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...\\n    print(metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', 'from sklearn.metrics import classification_repor...tric(new_test_predictions, new_test_data.severe))', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)'], 'Out': {5:   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , 6: ((194949, 8), (21661, 8)), 8: array([[ 1.        ,  0.        ,  0.        ,  ...\n         0.        ,  0.        , -0.86000031]]), 10:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , 14:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  }, 'RANDOM_SEED': 33, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, '_':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_10':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_14':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_5':   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , ...}\n        self.user_ns = {'ClassWeightSampler': <class '__main__.ClassWeightSampler'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'In': ['', \"new_test_data = pandas.read_csv('./casualty_test...ta.severe.astype('int')\\nnew_test_data.head()\\n\\n = \", \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", \"get_ipython().magic('matplotlib inline')\\n\\nimport...\\nmatplotlib.style.use('ggplot')\\n\\nRANDOM_SEED = 33\", \"# data_no_unknown.loc[np.logical_not(data_no_unk...pedestrian_movement), 'pedestrian_movement'] = ''\", \"casualty_data = pandas.read_csv('./casualty_trai...known.severe.astype('int')\\ndata_no_unknown.head()\", 'from sklearn.model_selection import train_test_s..., ) #  train_size = 0.25,\\ntrain.shape, test.shape', \"# casualty_data.loc[casualty_data.age == 'Unknown'].groupby('casualty_class').sum()\", \"data_mapper = DataFrameMapper([\\n    ('casualty_c...a_mapper.transformed_names_)\\ntransformed_data[:5]\", 'from sklearn.model_selection import RandomizedSe...       print(k, np.average(cv_scores), cv_scores)', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor....__name__, metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...\\n    print(metric(test_predictions, test.severe))', 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', \"new_test_data = pandas.read_csv('./casualty_test...st_data.severe.astype('int')\\nnew_test_data.head()\", 'from sklearn.metrics import classification_repor...nt(metric(new_test_predictions, new_test.severe))', 'from sklearn.metrics import classification_repor...tric(new_test_predictions, new_test_data.severe))', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)', 'from sklearn.model_selection import RandomizedSe...y=train.severe)\\n    report(search_cv.cv_results_)'], 'Out': {5:   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , 6: ((194949, 8), (21661, 8)), 8: array([[ 1.        ,  0.        ,  0.        ,  ...\n         0.        ,  0.        , -0.86000031]]), 10:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , 14:   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  }, 'RANDOM_SEED': 33, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, '_':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_10':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_14':   casualty_class  gender age  severe pedestrian_...010  \n3         car  2011  \n4         car  2007  , '_5':   casualty_class  gender age  severe pedestrian_...006  \n3  pedestrian  2012  \n4   motorbike  2010  , ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/guydavidson/projects/minerva/notebooks/CS156/<ipython-input-18-8492c359b945> in <module>()\n     35     search_cv = RandomizedSearchCV(logit_search_pipe, n_iter=10, scoring='recall', n_jobs=4, \n     36                                    verbose=1, random_state=RANDOM_SEED,\n     37                                    param_distributions={'ridge__class_weight': sampler,\n     38 #                                                         'logit__C': uniform(loc=1, scale=10) \n     39                                                        })\n---> 40     search_cv.fit(X=train, y=train.severe)\n     41     report(search_cv.cv_results_)\n     42 \n     43 \n     44 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=None, error_score='raise',...rn_train_score=True, scoring='recall', verbose=1), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...n_train_score=True, scoring='recall', verbose=1)>\n        X =        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns]\n        y = 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=RandomizedSearchCV(cv=None, error_score='raise',...rn_train_score=True, scoring='recall', verbose=1), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Sep 14 18:16:12 2017\nPID: 4332              Python 3.6.2: /Users/guydavidson/anaconda/bin/python\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]),        casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], 106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, make_scorer(recall_score), array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), array([    0,     1,     2, ..., 65014, 65015, 65016]), 1, {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), X=       casualty_class  gender age  severe  pedes...           car  2012  \n\n[194949 rows x 8 columns], y=106419    0\n144470    0\n169593    0\n190066    0\n...24697    0\n10387     0\nName: severe, dtype: int64, scorer=make_scorer(recall_score), train=array([ 64740,  64742,  64743, ..., 194946, 194947, 194948]), test=array([    0,     1,     2, ..., 65014, 65015, 65016]), verbose=1, parameters={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        parameters = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **kwargs={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...01,\n          verbose=True, warm_start=False))])>\n        kwargs = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), steps_attr='steps', **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...01,\n          verbose=True, warm_start=False))])>\n        params = {'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/guydavidson/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))]), **params={'ridge__class_weight': {0: 1, 1: array([ 5.97020255])}})\n    277                 name, sub_name = split\n    278                 if name not in valid_params:\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n--> 282                                      (name, self))\n        name = 'ridge'\n        self = Pipeline(steps=[('featurize', DataFrameMapper(de...001,\n          verbose=True, warm_start=False))])\n    283                 sub_object = valid_params[name]\n    284                 sub_object.set_params(**{sub_name: value})\n    285             else:\n    286                 # simple objects case\n\nValueError: Invalid parameter ridge for estimator Pipeline(steps=[('featurize', DataFrameMapper(default=False, df_out=False,\n        features=[('casualty_class', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), ('gender', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), {}), (['age'], StandardScaler(copy=True, with_mean=True...'l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=True, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "ridge_search_pipe = sklearn.pipeline.Pipeline([\n",
    "    ('featurize', data_mapper),\n",
    "    ('ridge', sklearn.linear_model.RidgeClassifierCV())\n",
    "])\n",
    "\n",
    "from collections import namedtuple\n",
    "ClassWeightSampler = namedtuple('ClassWeightSampler', 'rvs')\n",
    "\n",
    "def sample_class_weights(loc=0, scale=1, size=1, random_state=None):\n",
    "    return {0: 1, 1: uniform.rvs(loc=1, scale=20, size=size, random_state=random_state)}\n",
    "\n",
    "sampler = ClassWeightSampler(rvs=sample_class_weights)\n",
    "\n",
    "# report function from http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    search_cv = RandomizedSearchCV(logit_search_pipe, n_iter=10, scoring='recall', n_jobs=4, \n",
    "                                   verbose=1, random_state=RANDOM_SEED,\n",
    "                                   param_distributions={'ridge__class_weight': sampler,\n",
    "#                                                         'logit__C': uniform(loc=1, scale=10) \n",
    "                                                       })\n",
    "    search_cv.fit(X=train, y=train.severe)\n",
    "    report(search_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
