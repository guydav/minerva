{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability distribution\n",
    "Assuming the coins are equally likely:\n",
    "\n",
    "P(heads) = $\\frac{1}{2}\\theta_1 + \\frac{1}{2}\\theta_2$\n",
    "\n",
    "## E-step\n",
    "\n",
    "First, we should derive an expression for $q(h | v) = P(h | v, \\theta^{t-1})$\n",
    "\n",
    "For each possible value of $h \\in {1, 2}$, $q(h |v) \\propto \\binom{v_n}{v_k} (\\theta^{t-1}_{h})^{v_k} (1 - \\theta^{t-1}_{h})^{v_n - v_k}$ where $v_n$ is the number of throws observed, $v_k$ is the number of heads observed, and $\\theta^{t-1}_{h}$ is the current probability of heads for the coin we denote by the current value of $h$. To arrive at the exact probability, we normalize by dividing by the sum of both values of $h$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import comb\n",
    "\n",
    "def e_step(theta, throws, heads):\n",
    "    \"\"\"\n",
    "    throws: a list of the number of throws thrown using the coin chosen at each iteration (v_n)\n",
    "    heads: the number of heads observed in each iteration (v_k)\n",
    "    theta: the current value of theta (\\theta^{t-1})\n",
    "    \"\"\"\n",
    "    q = []\n",
    "    for n, k in zip(throws, heads):\n",
    "        n_choose_k = comb(n, k)\n",
    "        probs = [ n_choose_k * (p ** k) * ((1 - p) ** (n - k)) for p in theta]\n",
    "        norm = sum(probs)\n",
    "        probs = [ q / norm for q in probs ] \n",
    "        q.append(probs)\n",
    "        \n",
    "    return q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0051119646305962871, 0.99488803536940373], [0.99991090315086062, 8.9096849139461371e-05], [0.99772154495217003, 0.0022784550478299678], [0.22857142857142859, 0.77142857142857135], [0.40000000000000002, 0.59999999999999998], [0.98857110968498008, 0.011428890315019964], [0.99235160222356256, 0.007648397776437491], [0.22857142857142859, 0.77142857142857135], [0.5, 0.5], [4.0795824582382401e-11, 0.99999999995920419], [0.88363636363636366, 0.11636363636363642], [0.0010139301291582788, 0.99898606987084171], [0.22857142857142865, 0.77142857142857135], [0.00020044558672603654, 0.99979955441327395], [0.30769230769230776, 0.69230769230769229], [0.99235160222356245, 0.0076483977764374893], [0.11636363636363641, 0.88363636363636355], [0.16494845360824748, 0.8350515463917525], [0.99999999647126081, 3.5287392148869218e-09], [1.1909494750432793e-08, 0.99999998809050517]]\n",
      "(0.0051119646305962871, 0.99991090315086062, 0.99772154495217003, 0.22857142857142859, 0.40000000000000002, 0.98857110968498008, 0.99235160222356256, 0.22857142857142859, 0.5, 4.0795824582382401e-11, 0.88363636363636366, 0.0010139301291582788, 0.22857142857142865, 0.00020044558672603654, 0.30769230769230776, 0.99235160222356245, 0.11636363636363641, 0.16494845360824748, 0.99999999647126081, 1.1909494750432793e-08)\n",
      "(0.99488803536940373, 8.9096849139461371e-05, 0.0022784550478299678, 0.77142857142857135, 0.59999999999999998, 0.011428890315019964, 0.007648397776437491, 0.77142857142857135, 0.5, 0.99999999995920419, 0.11636363636363642, 0.99898606987084171, 0.77142857142857135, 0.99979955441327395, 0.69230769230769229, 0.0076483977764374893, 0.88363636363636355, 0.8350515463917525, 3.5287392148869218e-09, 0.99999998809050517)\n"
     ]
    }
   ],
   "source": [
    "throws = [41, 43, 23, 23, 1, 23, 36, 37, 2, 131, 5, 29, 13, 47, 10, 58, 15, 14, 100, 113]\n",
    "heads = [14, 33, 19, 10, 0, 17, 24, 17, 1, 36, 5, 6, 5, 13, 4, 35, 5, 5, 74, 34]\n",
    "\n",
    "print(e_step([0.6, 0.4], throws, heads))\n",
    "\n",
    "for x in zip(*e_step([0.6, 0.4], throws, heads)):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M-step\n",
    "\n",
    "To compute the M-step, we should start by writing down an expression for the energy. By definition, the energy is $ \\sum_{n=1}^{N} \\langle \\log p(h^n, v^n | \\theta) \\rangle_{q(h^n | v^n)} $.\n",
    "\n",
    "Since $q$ is discrete, we can think about it as $ \\sum_{n=1}^{N} \\sum_{i=1}^{H} \\log p(v^n | h^n=i, \\theta) q(h^n=i | v^n) $, where $H$ is the total number of possibilities for $h$.\n",
    "\n",
    "In this case, the probability is binomial, $p(v^n | h^n=i, \\theta) = \\binom{v^n_n}{v^n_k} (\\theta^{t}_{i})^{v^n_k} (1 - \\theta^{t}_{i})^{v^n_n - v^n_k} $, leaving us looking for $\\theta^t$ that maximizes $ \\sum_{i=1}^{H} \\sum_{n=1}^{N} q(h^n=i | v^n) \\log \\Big( \\binom{v^n_n}{v^n_k} (\\theta^{t}_{i})^{v^n_k} (1 - \\theta^{t}_{i})^{v^n_n - v^n_k} \\Big) $. Note the switch in order of summation, to consider each $\\theta_i$ separately, since the two are independent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimze, we can differentiate and set to zero (for a particular $\\theta_i$):\n",
    "\\begin{align*}\n",
    "0 &= \\frac{d}{d\\theta^t} \\Big[ \\sum_{n=1}^{N} q(h^n=i | v^n) \\log \\Big( \\binom{v^n_n}{v^n_k} (\\theta^{t}_{i})^{v^n_k} (1 - \\theta^{t}_{i})^{v^n_n - v^n_k} \\Big) \\Big] \\\\\n",
    "&= \\sum_{n=1}^{N} q(h^n=i | v^n) \\frac{d}{d\\theta^t} \\Big[ \\log \\Big( \\binom{v^n_n}{v^n_k} (\\theta^{t}_{i})^{v^n_k} (1 - \\theta^{t}_{i})^{v^n_n - v^n_k} \\Big) \\Big] \\\\\n",
    "&= \\sum_{n=1}^{N} q(h^n=i | v^n) \\frac{d}{d\\theta^t} \\Big[ \\log \\Big( \\binom{v^n_n}{v^n_k} \\Big) + (v^n_k) \\log \\Big( (\\theta^{t}_{i}) \\Big) + (v^n_n - v^n_k) \\log \\Big( (1 - \\theta^{t}_{i}) \\Big) \\Big] \\\\\n",
    "&= \\sum_{n=1}^{N} q(h^n=i | v^n) \\Big[ \\frac{v^n_k}{\\theta^{t}_{i}} - \\frac{v^n_n - v^n_k}{1 - \\theta^{t}_{i}} \\Big] \\\\\n",
    "&= \\sum_{n=1}^{N} q(h^n=i | v^n) \\frac{v^n_k}{\\theta^{t}_{i}} - \\sum_{n=1}^{N} q(h^n=i | v^n)  \\frac{v^n_n - v^n_k}{1 - \\theta^{t}_{i}} \\\\\n",
    "\\frac{1}{\\theta^{t}_{i}} \\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_k) &= \\frac{1}{1 - \\theta^{t}_{i}}\\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_n - v^n_k) \\\\\n",
    "\\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_k) &= \\theta^{t}_{i} \\Big( \\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_n - v^n_k) + \\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_k) \\Big) \\\\\n",
    "\\theta^{t}_{i} &= \\frac{\\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_k)}{\\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_n - v^n_k) + \\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_k)} \\\\\n",
    "\\theta^{t}_{i} &= \\frac{\\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_k)}{\\sum_{n=1}^{N} q(h^n=i | v^n) (v^n_n)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the $\\theta^{t}_{i}$ that optimizes the given $q(h | v)$ is the ratio between a weighted sum of heads and a weighted sum of tosses, each trial weighted by the probability the current coin was used for it under $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def m_step(q, throws, heads):\n",
    "    theta = []\n",
    "    for q_for_theta in zip(*q):\n",
    "        numerator = sum([v_k * q_h for v_k, q_h in zip(heads, q_for_theta)])\n",
    "        denominator = sum([v_n * q_h for v_n, q_h in zip(throws, q_for_theta)])\n",
    "        theta.append(numerator / denominator)\n",
    "        \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58252000809913906, 0.3806030183001759]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_step(e_step([0.51, 0.49], throws, heads), throws, heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def em(theta_zero, data=(throws, heads), max_t=1e3, min_diff=1e-7):\n",
    "    theta = theta_zero\n",
    "    for t in range(int(max_t)):\n",
    "        q = e_step(theta, *data)\n",
    "        next_theta = m_step(q, *data)\n",
    "        if sum([abs(n - t) for n, t in zip(next_theta, theta)]) < min_diff:\n",
    "            print('Converged after {t} iterations, breaking'.format(t=t + 1))\n",
    "            return next_theta\n",
    "            \n",
    "        theta = next_theta\n",
    "            \n",
    "    return theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 10 iterations, breaking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.71253192057209336, 0.31411465036724373]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em([0.51, 0.49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 9 iterations, breaking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31411465064967259, 0.71253192173588253]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em([0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 2 iterations, breaking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46727748691099474, 0.46727748691099474]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em([0.25, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability distribution given bias\n",
    "If we're more likely to pick a particular coin:\n",
    "\n",
    "P(heads) = $\\frac{\\phi_1}{2}\\theta_1 + \\frac{\\phi_2}{2}\\theta_2$, where $\\phi$ is the mixture weight.\n",
    "\n",
    "## E-step\n",
    "To re-derive the E-step, we simply weight by the previous value of $\\phi$:\n",
    "\n",
    "$q(h |v) \\propto \\phi^{t-1}_h \\binom{v_n}{v_k} (\\theta^{t-1}_{h})^{v_k} (1 - \\theta^{t-1}_{h})^{v_n - v_k}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def e_step_with_bias(theta, phi, throws, heads):\n",
    "    \"\"\"\n",
    "    throws: a list of the number of throws thrown using the coin chosen at each iteration (v_n)\n",
    "    heads: the number of heads observed in each iteration (v_k)\n",
    "    theta: the current value of theta (\\theta^{t-1})\n",
    "    phi: the current value of phi (\\phi^{t-1}), a vector the same length as theta\n",
    "    \"\"\"\n",
    "    q = []\n",
    "    for n, k in zip(throws, heads):\n",
    "        n_choose_k = comb(n, k)\n",
    "        probs = [ ph * n_choose_k * (p ** k) * ((1 - p) ** (n - k)) for p, ph in zip(theta, phi)]\n",
    "        norm = sum(probs)\n",
    "        probs = [ q / norm for q in probs ] \n",
    "        q.append(probs)\n",
    "        \n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M-step\n",
    "\n",
    "To work out the M-step, we note the probability changes, as it is also multiplied by a factor of $\\phi_h$. Note that the derivation for $\\theta$ doesn't change, as like the binomial factor, $\\frac{d\\phi_h}{d\\theta} = 0$. Deriving for $\\phi$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "0 &= \\frac{d}{d\\phi^t} \\Big[  \\sum_{i=1}^{H} \\sum_{n=1}^{N} q(h^n=i | v^n) \\log \\Big( \\phi^t_i \\binom{v^n_n}{v^n_k} (\\theta^{t}_{i})^{v^n_k} (1 - \\theta^{t}_{i})^{v^n_n - v^n_k} \\Big) \\Big] \\\\\n",
    "&=  \\sum_{i=1}^{H} \\sum_{n=1}^{N} q(h^n=i | v^n) \\frac{d}{d\\phi^t} \\Big[ \\log \\Big( \\phi^t_i \\binom{v^n_n}{v^n_k} (\\theta^{t}_{i})^{v^n_k} (1 - \\theta^{t}_{i})^{v^n_n - v^n_k} \\Big) \\Big] \\\\\n",
    "&= \\sum_{i=1}^{H} \\sum_{n=1}^{N} q(h^n=i | v^n) \\frac{d}{d\\phi^t} \\Big[ \\log (\\phi^t_i) +\\log \\Big( \\binom{v^n_n}{v^n_k} \\Big) + (v^n_k) \\log \\Big( (\\theta^{t}_{i}) \\Big) + (v^n_n - v^n_k) \\log \\Big( (1 - \\theta^{t}_{i}) \\Big) \\Big] \\\\\n",
    "&= \\sum_{i=1}^{H} \\sum_{n=1}^{N} q(h^n=i | v^n) \\Big[ \\frac{1}{\\phi^{t}_{i}}\\Big] \\\\\n",
    "&= \\sum_{n=1}^{N} q(h^n=1 | v^n) \\Big[ \\frac{1}{\\phi^{t}_{1}}\\Big] + \\sum_{n=1}^{N} q(h^n=2 | v^n) \\Big[ \\frac{1}{\\phi^{t}_{2}}\\Big]  \\\\\n",
    "&= \\frac{1}{\\phi^{t}_{1}} \\sum_{n=1}^{N} q(h^n=1 | v^n) + \\frac{1}{\\phi^{t}_{2}}\\sum_{n=1}^{N} q(h^n=2 | v^n) \\\\\n",
    "&\\text{Recall that } \\phi_1 + \\phi_2 = 1: \\\\\n",
    "&= \\frac{1}{\\phi^{t}_{1}} \\sum_{n=1}^{N} q(h^n=1 | v^n) + \\frac{1}{1 - \\phi^{t}_{1}}\\sum_{n=1}^{N} q(h^n=2 | v^n) \\\\\n",
    "&= (1 - \\phi^{t}_{1}) \\sum_{n=1}^{N} q(h^n=1 | v^n) + (\\phi^{t}_{1}) \\sum_{n=1}^{N} q(h^n=2 | v^n) \\\\\n",
    "\\sum_{n=1}^{N} q(h^n=1 | v^n) &= \\phi^{t}_{1} \\sum_{n=1}^{N} q(h^n=1 | v^n) - \\phi^{t}_{1} \\sum_{n=1}^{N} q(h^n=2 | v^n) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
