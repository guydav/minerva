{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from datetime import datetime\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import warnings\n",
    "import timeit\n",
    "from collections import defaultdict, OrderedDict\n",
    "import tabulate\n",
    "import time\n",
    "import GPy\n",
    "from IPython.display import display\n",
    "\n",
    "timeit.template = \"\"\"\n",
    "def inner(_it, _timer{init}):\n",
    "    {setup}\n",
    "    _t0 = _timer()\n",
    "    for _i in _it:\n",
    "        retval = {stmt}\n",
    "    _t1 = _timer()\n",
    "    return _t1 - _t0, retval\n",
    "\"\"\"\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTENTS_OPTIONS = ('CONTENTS', 'Contents')\n",
    "IGNORE_CONTENTS = ('NOTES', ':', 'CONTENTS', 'Contents', 'Contents:')\n",
    "SKIP_CONTENTS = ('APPENDIX', 'GLOSSARY')\n",
    "TERMINATION = '*** END OF THIS PROJECT GUTENBERG EBOOK'\n",
    "\n",
    "def split_book_by_contents(path, contents=None):\n",
    "    chapters = OrderedDict()\n",
    "    \n",
    "    with open(path) as book_file:\n",
    "        book = book_file.read()\n",
    "        \n",
    "        if not contents:\n",
    "            contents_start = -1\n",
    "            for c in CONTENTS_OPTIONS:\n",
    "                idx = book.find(c)\n",
    "                if -1 != idx:\n",
    "                    contents_start = idx + len(c)\n",
    "                    break\n",
    "\n",
    "            if -1 == contents_start:\n",
    "                raise ValueError('Failed to find table of contents, aborting...')\n",
    "\n",
    "            contents_end = book.find('\\n' * 4, contents_start)\n",
    "            contents = book[contents_start : contents_end].split('\\n')\n",
    "            contents = [c.strip() for c in contents]\n",
    "            contents = [c for c in contents if c and c not in IGNORE_CONTENTS]\n",
    "            start_index = contents_end\n",
    "            \n",
    "        else:\n",
    "            start_index = book.find(contents[0]) - 1\n",
    "        \n",
    "        contents_and_end = contents + [TERMINATION]\n",
    "        \n",
    "        for start_title, end_title in zip(contents, contents[1:]):\n",
    "            if start_title in SKIP_CONTENTS: continue\n",
    "                \n",
    "            chapter_start = book.find(start_title, start_index) + len(start_title)\n",
    "            chapter_end = book.find(end_title, chapter_start)\n",
    "            chapters[start_title] = book[chapter_start : chapter_end].strip()\n",
    "            \n",
    "            start_index = chapter_end - 1\n",
    "        \n",
    "        \n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# print_top_words stolen shamelessly from \n",
    "# http://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "def extract_fit_print(book_path, contents=None, n_components=20, min_df=2, split_chapters=None):\n",
    "    book = split_book_by_contents(book_path, contents)\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=min_df, stop_words='english')\n",
    "    chapters = [book[c] for c in book]\n",
    "    \n",
    "    if split_chapters:\n",
    "        chapter_words = [chapter.split() for chapter in chapters]\n",
    "        chapter_lengths = [len(chap) for chap in chapter_words]\n",
    "        chapter_ranges = [[int(length * i) for i in range(split_chapters + 1)] for length in chapter_lengths]\n",
    "        chapter_splits = [[' '.join(split[start : end]) for start, end in zip(cr, cr[1:])] \n",
    "                          for split, cr in zip(chapter_words, chapter_ranges)]\n",
    "        chapters = [s for split_chapter in chapter_splits for s in split_chapter]\n",
    "            \n",
    "    count_vectors = tf_vectorizer.fit_transform(chapters)\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=n_components, max_iter=20)\n",
    "    lda.fit(count_vectors)\n",
    "    \n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    print_top_words(lda, tf_feature_names, 10)\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thou things thy unto man nature thee thyself life doth\n",
      "Topic #1: thou things unto thy man thee doth good thyself nature\n",
      "Topic #2: thou things unto thee thy man doth nature whatsoever world\n",
      "Topic #3: thou unto things thee nature natural life doth thy person\n",
      "Topic #4: thou thy things unto doth whatsoever nature world shall good\n",
      "Topic #5: thou things man nature thy unto thee good doth thyself\n",
      "Topic #6: thou man things unto thy doth nature good did thee\n",
      "Topic #7: thou things unto man thee thy nature doth world thyself\n",
      "Topic #8: thou things thyself man says art life nature fable let\n",
      "Topic #9: good winds ingenuous personal cured requisite whereof roman gain seeks\n",
      "Topic #10: things thou unto thy thee doth man shall thyself whatsoever\n",
      "Topic #11: thou things unto thee good thy hath man doth constitution\n",
      "Topic #12: thou things unto thy man thee nature doth good thyself\n",
      "Topic #13: things thou thy men nature unto man mind did kind\n",
      "Topic #14: thou things man unto men good nature thy time thee\n",
      "Topic #15: unto thou things thy man thee good doth nature whatsoever\n",
      "Topic #16: things good kind needs having reproach charges commentaries privately long\n",
      "Topic #17: thou unto things thy thee thyself good doth nature man\n",
      "Topic #18: unto nature things man thou did good thy men doth\n",
      "Topic #19: turned associated places purposed learn multitude reduce family war hold\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=20,\n",
       "             mean_change_tol=0.001, n_components=20, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_fit_print(r'data/books/meditations.txt', split_chapters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: constitution executive federal legislative powers ought members convention national representatives\n",
      "Topic #1: national constitution union general ought convention members great body court\n",
      "Topic #2: national union constitution public general authority great duties taxation influence\n",
      "Topic #3: ought executive great legislative nations national general public common constitution\n",
      "Topic #4: constitution cases union citizens ought great number federal shall case\n",
      "Topic #5: exclusion ill magistrate office perpetual entertain men man station predecessor\n",
      "Topic #6: courts cases constitution court authority law jurisdiction jury united trial\n",
      "Topic #7: constitution federal authority united cases convention body representatives general public\n",
      "Topic #8: executive legislative constitution union powers members men great department authority\n",
      "Topic #9: union national public great general time men constitution nations powers\n",
      "Topic #10: federal members authority general governments national union particular powers constitution\n",
      "Topic #11: national united respect body war senate great executive number powers\n",
      "Topic #12: executive constitution authority general powers legislative union federal great subject\n",
      "Topic #13: powers constitution members public union great legislative authority national time\n",
      "Topic #14: representatives number affairs treaties time elections knowledge members federal constitution\n",
      "Topic #15: union ought war men national general situation authority common particular\n",
      "Topic #16: union convention great national america congress number constitution men executive\n",
      "Topic #17: union national federal powers proper governments constitution political authority citizens\n",
      "Topic #18: president senate representatives executive number union shall body great constitution\n",
      "Topic #19: cities union members provinces confederacy general macedon authority federal greece\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=20,\n",
       "             mean_change_tol=0.001, n_components=20, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federalist_contents = ['FEDERALIST No. {idx}'.format(idx=i + 1) for i in range(84)]\n",
    "extract_fit_print(r'data/books/federalist.txt', federalist_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: poe allan edgar ebook works gutenberg volume edition raven project\n",
      "Topic #1: 2016 utf david note english www 2008 restrictions added project\n",
      "Topic #2: language use endnotes title start purloined author encoding 2148 contents\n",
      "Topic #3: release www added produced letter works whatsoever updated end english\n",
      "Topic #4: david set 2016 terms edition license use date griswold contents\n",
      "Topic #5: gutenberg restrictions project 19 release start added title use encoding\n",
      "Topic #6: contents included set use terms away project title start gutenberg\n",
      "Topic #7: edgar cost volume whatsoever october away contents language included 2008\n",
      "Topic #8: 19 included 2008 allan poe set terms language david letter\n",
      "Topic #9: set widger edition updated start title ebook cost license ii\n",
      "Topic #10: www endnotes english author volume use poe release widger restrictions\n",
      "Topic #11: 2148 note away edition release org restrictions ii october edgar\n",
      "Topic #12: notes letter widger ii whatsoever produced restrictions set allan copy\n",
      "Topic #13: date widger www copy edgar works 2016 license letter ii\n",
      "Topic #14: ebook redactor ii title october letter purloined use updated 2008\n",
      "Topic #15: added letter title ebook whatsoever copy cost notes poe volume\n",
      "Topic #16: october david end language redactor 2016 terms gutenberg added character\n",
      "Topic #17: griswold works language volume set notes terms redactor endnotes start\n",
      "Topic #18: 19 encoding cost away purloined restrictions language ebook english widger\n",
      "Topic #19: allan letter griswold notes works release english ii title terms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=20,\n",
       "             mean_change_tol=0.001, n_components=20, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_fit_print(r'data/books/poe.txt', min_df=1, split_chapters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: villefort little grows performed sympathy saint mind swollen getting unknown\n",
      "Topic #1: fernand said dantès caderousse danglars mercédès edmond know man young\n",
      "Topic #2: said villefort man dantès mercédès danglars fernand caderousse yes edmond\n",
      "Topic #3: villefort said dantès king know renée cried marquise saint sire\n",
      "Topic #4: dantès said villefort know door sire jailer police minister letter\n",
      "Topic #5: require father invitation said sail méran piastres pharaon land firing\n",
      "Topic #6: danglars caderousse quite 1st tried dantès did ah water laden\n",
      "Topic #7: dantès replied door saw said jailer mercédès did gendarme young\n",
      "Topic #8: said dantès fernand mercédès young danglars man edmond did sire\n",
      "Topic #9: dantès grasped said villefort mercédès sweat sentiments tremulous advanced confirmed\n",
      "Topic #10: villefort said know father man police sire dantès heart king\n",
      "Topic #11: dear sire man said king majesty father villefort duke louis\n",
      "Topic #12: villefort renée marquise king marquis napoleon saint madame méran law\n",
      "Topic #13: villefort sire said minister man sir police majesty king louis\n",
      "Topic #14: villefort dear said know noirtier yes general father day quesnel\n",
      "Topic #15: dantès calm villefort miles belonged greatly beauty grumbling hoping sympathetic\n",
      "Topic #16: dantès villefort said fernand danglars know caderousse man mercédès letter\n",
      "Topic #17: silence laid uniform gain awaiting speedily sad ceased french skin\n",
      "Topic #18: said dantès danglars fernand caderousse like man mercédès know replied\n",
      "Topic #19: fernand said danglars caderousse dantès edmond mercédès man time girl\n",
      "Topic #20: dantès said danglars morrel replied edmond father caderousse man old\n",
      "Topic #21: danglars fernand said health caderousse dantès love mercédès pen hallo\n",
      "Topic #22: ambitious certainty given announce problem oppose dignity hearted constantly travelling\n",
      "Topic #23: said man villefort dantès yes father old sire king majesty\n",
      "Topic #24: dantès man young yes morrel said father danglars door dear\n",
      "Topic #25: danglars dantès fernand caderousse mercédès villefort said yes accident king\n",
      "Topic #26: decorated persons cut continual ingenious depended illusions vessels advise augmented\n",
      "Topic #27: applied villefort trial asked stillness fight piastres apply grotesque sink\n",
      "Topic #28: hoped continually remaining appearance weight reckoning near collect dealer heavily\n",
      "Topic #29: villefort said dantès letter man danglars fernand know replied morrel\n",
      "Topic #30: said sire king blacas louis majesty duke villefort minister xviii\n",
      "Topic #31: marquise cavern bonapartist heat glad skill punishment pointed dead bursting\n",
      "Topic #32: dantès said fernand danglars mercédès know caderousse man villefort replied\n",
      "Topic #33: morrel choice danglars enthusiasm bay catalans outward aided calculated oh\n",
      "Topic #34: fernand said mercédès man edmond danglars dantès young caderousse ah\n",
      "Topic #35: action resistance admiration friendly dress corrupt sunday using violence wear\n",
      "Topic #36: dantès morrel mercédès detain captain feel said course caderousse jealousy\n",
      "Topic #37: spared got sold drowned rapid recalling pressed continually fine devoid\n",
      "Topic #38: villefort dantès yes said king renée mercédès packet saint come\n",
      "Topic #39: dantès said villefort marquise young danglars man did edmond méran\n",
      "Topic #40: dantès said caderousse abbé man edmond did replied poor know\n",
      "Topic #41: dantès villefort said man danglars yes know replied young saw\n",
      "Topic #42: villefort sire said minister louis king xviii know man police\n",
      "Topic #43: villefort sire said king louis majesty minister police xviii know\n",
      "Topic #44: conducting lose beating elevated drops pervaded bravo disclosure myrtle overcome\n",
      "Topic #45: dantès said door villefort know mercédès took like black marquis\n",
      "Topic #46: dantès jailer advanced convinced offering protect asked does long insanity\n",
      "Topic #47: said caderousse danglars fernand villefort marquise like replied man king\n",
      "Topic #48: dantès said mercédès caderousse yes gendarme saw man jailer boat\n",
      "Topic #49: villefort said man police know danglars father door black bonaparte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comc_lda = extract_fit_print(r'data/books/count_of_monte_cristo.txt', split_chapters=10, n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    92.22224406,     92.85245253,     93.97565776,     92.52839384,\n",
       "           92.75169741,     92.23859345,     92.20997308,     92.37006683,\n",
       "           92.82955542,     92.21145197,     92.55922885,     92.39084862,\n",
       "          581.66755588,     93.00458192,     92.50545424,     92.19525675,\n",
       "           93.28570705,     92.13317696,     92.66002947,     93.09578361,\n",
       "           93.58961007,     94.76718033,     92.12700038,     93.15508932,\n",
       "           92.42536493,     92.28001317,     92.10429422,     92.20191818,\n",
       "           92.13184027,     93.05178921,     92.8698482 ,     92.14644615,\n",
       "           93.29194898,     92.18926615,     92.55154106,     92.11162521,\n",
       "           92.27269324,     92.1336747 ,     92.36781736,     92.4770595 ,\n",
       "        33570.34820202,     93.22581873,     92.38976125,   2186.09564104,\n",
       "           92.13866829,     92.39287529,     92.25193521,     92.51903128,\n",
       "           92.94076458,     92.39121468])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(comc_lda.components_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
